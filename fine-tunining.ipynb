{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Import the important libraries**","metadata":{}},{"cell_type":"code","source":"import os\nfrom dataclasses import dataclass, field\nfrom typing import Optional\nimport torch\nfrom datasets import load_dataset, load_from_disk\nfrom transformers import (\nAutoModelForCausalLM,\nAutoTokenizer,\nBitsAndBytesConfig,\nHfArgumentParser,\nTrainingArguments\n)\nfrom tqdm.notebook import tqdm\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer\nfrom huggingface_hub import login","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hf_token = \"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\"\nlogin(token=hf_token)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_dataset(\"Amod/mental_health_counseling_conversations\", split=\"train\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Let's convert HF dataset into DataFrame using Pandas**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf_dataset = pd.DataFrame(dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_dataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_dataset.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def formated_row(row):\n    question = row['Context']\n    answer = row['Response']\n    formated_string = f\"[INST] {question} [/INST] {answer}\"\n    return formated_string","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_dataset[\"formatted\"] = df_dataset.apply(formated_row, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_dataset[\"formatted\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_dataset = df_dataset.rename(columns = {'formatted': 'Text'})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_dataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_dataset = new_dataset[[\"Text\"]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_dataset.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_dataset.to_csv(\"formatted_data.csv\", index = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_dataset = load_dataset(\"csv\", data_files=\"formatted_data.csv\", split=\"train\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(training_dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Fine tunining**","metadata":{}},{"cell_type":"code","source":"base_model = \"NousResearch/Llama-2-7b-chat-hf\"\nnew_model = \"phi-2-mental-health\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\nforce_download=True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# bitsandbytes\nbnb_config = BitsAndBytesConfig(\n    load_in_4bits = True,\n    bnb_4bit_quant_type = \"nf4\",\n    bnb_4bit_compute_dtype = \"float16\",\n    bnb_4bit_use_double_quant = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load the base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=bnb_config,\n    device_map = {\"\": 0}\n)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir = \"./results\",\n    num_train_epochs= 1,\n    per_device_train_batch_size= 4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps = 0,\n    logging_steps = 25,\n    learning_rate = 2e-4,\n    weight_decay = 0.001,\n    fp16 = False,\n    bf16 = True,\n    max_grad_norm = 0.3,\n    max_steps = -1,\n    warmup_ratio = 0.03,\n    group_by_length= True,\n    lr_scheduler_type= \"cosine\",\n    report_to=\"tensorboard\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load LoRA configuration\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.01,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules = [\"wqkv\", \"fc1\", \"fc2\"]\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=training_dataset,\n    peft_config = peft_config,\n    dataset_text_field=\"Text\",\n    max_seq_length = None,\n    tokenizer = tokenizer,\n    args=training_arguments,\n    packing = False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train() ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}